{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt\nimport matplotlib.image as pltimg\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T11:59:22.871491Z","iopub.execute_input":"2022-05-20T11:59:22.871889Z","iopub.status.idle":"2022-05-20T11:59:24.427438Z","shell.execute_reply.started":"2022-05-20T11:59:22.871783Z","shell.execute_reply":"2022-05-20T11:59:24.426513Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv(\"../input/trainn/train.csv\")#file downloaded\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.429354Z","iopub.execute_input":"2022-05-20T11:59:24.429591Z","iopub.status.idle":"2022-05-20T11:59:24.580916Z","shell.execute_reply.started":"2022-05-20T11:59:24.429562Z","shell.execute_reply":"2022-05-20T11:59:24.579868Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Soru 1\nlebronFrame = df.loc[df[\"shoot player\"] == 'LeBron James']# dataframe consisting only of leBron James's shots\nlebronFrame","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.582149Z","iopub.execute_input":"2022-05-20T11:59:24.582404Z","iopub.status.idle":"2022-05-20T11:59:24.625863Z","shell.execute_reply.started":"2022-05-20T11:59:24.582372Z","shell.execute_reply":"2022-05-20T11:59:24.624746Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Soru 2\ndf.columns #columns of df\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.628749Z","iopub.execute_input":"2022-05-20T11:59:24.629442Z","iopub.status.idle":"2022-05-20T11:59:24.637001Z","shell.execute_reply.started":"2022-05-20T11:59:24.629386Z","shell.execute_reply":"2022-05-20T11:59:24.636077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.count() #full data count of df\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.638419Z","iopub.execute_input":"2022-05-20T11:59:24.638688Z","iopub.status.idle":"2022-05-20T11:59:24.666870Z","shell.execute_reply.started":"2022-05-20T11:59:24.638656Z","shell.execute_reply":"2022-05-20T11:59:24.665988Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n df.describe() # percentiles of df\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.668251Z","iopub.execute_input":"2022-05-20T11:59:24.668502Z","iopub.status.idle":"2022-05-20T11:59:24.717788Z","shell.execute_reply.started":"2022-05-20T11:59:24.668472Z","shell.execute_reply":"2022-05-20T11:59:24.717138Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Soru 3\ndf.head()\n# there is column for extra index value\n# some columns have nan values\n# object values more than others\n# There may be a type mismatch in the data","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.719006Z","iopub.execute_input":"2022-05-20T11:59:24.719480Z","iopub.status.idle":"2022-05-20T11:59:24.750970Z","shell.execute_reply.started":"2022-05-20T11:59:24.719421Z","shell.execute_reply":"2022-05-20T11:59:24.749998Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Soru 4\ndf.shape # count of rows and columns","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.752692Z","iopub.execute_input":"2022-05-20T11:59:24.753547Z","iopub.status.idle":"2022-05-20T11:59:24.760246Z","shell.execute_reply.started":"2022-05-20T11:59:24.753490Z","shell.execute_reply":"2022-05-20T11:59:24.759231Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Soru 5\ndf.dtypes #Variable types","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.761907Z","iopub.execute_input":"2022-05-20T11:59:24.762172Z","iopub.status.idle":"2022-05-20T11:59:24.778727Z","shell.execute_reply.started":"2022-05-20T11:59:24.762141Z","shell.execute_reply":"2022-05-20T11:59:24.777848Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Soru 6 \ndf['team']=df['My_Team'].values\ni=0\nwhile(i<len(df)):\n    if(df.loc[i,'home team']=='CLE'):\n        df.loc[i,'CLE team']=df.loc[i,'home team']\n    elif(df.loc[i,'away team']=='CLE'):\n        df.loc[i,'CLE team']=df.loc[i,'away team']\n    else:\n        df.loc[i,'CLE team']=0\n    i+=1\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:24.782335Z","iopub.execute_input":"2022-05-20T11:59:24.782886Z","iopub.status.idle":"2022-05-20T11:59:31.129940Z","shell.execute_reply.started":"2022-05-20T11:59:24.782835Z","shell.execute_reply":"2022-05-20T11:59:31.128831Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Soru 6\ndf2=df.loc[df['CLE team']=='CLE']\nplayer = df2[\"shoot player\"].unique()# cleveland players\ni = 0\nj = 0\nshot = 0\ncount=0\nindex = df2.reset_index() \ncle_player = index[\"shoot player\"]#The resulting data has also been reset to be able to use indexes.\nshot_score = index[\"current shot outcome\"]\nmax_score=0\nwhile(i<len(player)):\n    while(j < len(df2[\"current shot outcome\"])):\n        if(player[i]== cle_player[j]):\n            if(shot_score[j] == \"SCORED\"):#successful shot by the matched player\n                shot += 1\n                count+=1\n            else:\n                count+=1\n        j += 1\n        \n    highest_score = shot * 100 / count #successful shooting percentage\n    if(highest_score>max_score):\n        max_score=highest_score\n        name=player[i]\n        \n    j=0\n    i += 1\n    shot = 0\n    count=0\n    highest_score=0\n    \n    \nprint(\"\\n\")\nprint(\"Cleveland takımında en yüksek yüzdeyle şut atan oyuncunun ismi: \",name,\" VE  Başarı oranı :\",max_score )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:59:31.131484Z","iopub.execute_input":"2022-05-20T11:59:31.131846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 7\ndf2= df.loc[df[\"CLE team\"] == 'CLE']\nplayer = df2[\"shoot player\"].unique()\ni = 0\nwhile(i<len(player)):\n    df3 = df.loc[df[\"shoot player\"] == player[i]]\n    shot = df3['shoot player'].count()\n    print(player[i],\" \",shot,\"adet şut atmıştır\")\n    i+=1\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 8\nlebronFrame=df.loc[df[\"shoot player\"] == 'LeBron James']\nprint(\"Lebron James'in attığı şutların içerisinde maksimum x değerine sahip entry'nin indexi:\",lebronFrame[\"location x\"].idxmax())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 9\n# def distanceFinder(locX,locY):\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 10\nshot = df[\"shot type\"].unique()\nshotList = []# Shot Type List\nfor item in shots:\n    shotList.append(item)  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Şut Sayıları: \")\nj= 0\nwhile(j < len(shotList)):\n    count = df.loc[df[\"shot type\"] == shotList[j]]\n    shot_count = count[\"shot type\"].count()\n    print(shotList[j],\":\",shot_count)\n    j+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#alphabetically sorted list\nprint(\"\\n Alfabetik Sıralanmış Liste: \")\nprint(\"*************************************************\\n\")\nalphabetical = sorted(shotList)\nprint(alphabetical)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shot added \")\nprint(\"*************************************************\\n\")\nalphabetical.append(\"best shot\")\nprint(alphabetical)\n\nprint(\"Shot deleted \")\nprint(\"*************************************************\\n\")\nalphabetical.pop()\nprint(alphabetical)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bank Shot Index List\nbankShotId=[]\nj=0\nwhile (j <len(df)):\n    bankShot =df.loc[j,\"shot type\"].count('Bank Shot')\n    if(bankShot > 0): \n        bankShotId.append(j)\n    j+=1\nbankShotId","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 11\nshot = df[\"shot type\"].unique()\na_list=[]#list with letter a\ni=0\nwhile (i <len(shot)):\n    count =shot[i].count('a')#number of shots containing the letter a\n    if(count > 0): \n        a_list.append(shot[i])\n    i+=1\npd.Series(a_list)\na_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 12             \ndef locYFunc():\n return [x for x in df['location y'] if x >250]#those with location y greater than 250\nlocYFunc()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 13 \ndictionary = {}\nwhile(i<len(df['quarter'])):\n        if (df.loc[i,\"quarter\"] == 1):\n            df[\"quarter\"].replace({df[\"quarter\"][i]:\"ilk çeyrek\"})\n        elif (df.loc[i,\"quarter\"] == 2):\n            df[\"quarter\"].replace({df.loc[i,\"quarter\"]: \"ikinci çeyrek\"})\n        elif (df.loc[i,\"quarter\"] == 3):\n            df[\"quarter\"].replace({df[\"quarter\"][i]: \"üçüncü çeyrek\"})\n        elif (df.loc[i,\"quarter\"] == 4):\n            df[\"quarter\"].replace({df[\"quarter\"][i]: \"son Çeyrek\"})\n        i+=1\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" #Soru 14\n*** import pandas as pd***\n ‘xs’ fonksiyonu ‘loc’, ‘iloc’ gibi işlevsel fonksiyonları yerine getirebilir ve bize güzel avantajlar da sağlar.\n**Input:\ndf.xs('Group1').xs('Index1')**\nGruplanmış veriyi daha sonrada istenen indeksi vererek loc ve iloc benzeri işlevler görür.\nAvantajları verinin istenen yerdeki tam yerini bilmeden tek satırda kolayca elde edebilmenizi sağlar\n**df.xs('Index1', level = 'Indexes')['Column1']**","metadata":{}},{"cell_type":"code","source":"#Soru 15\ndf['team']=df['My_Team'].values\ni=0\nwhile(i<len(df)):\n    if(df.loc[i,'home team']=='CLE'):\n        df.loc[i,'team']=df.loc[i,'away team']\n    elif(df.loc[i,'away team']=='CLE'):\n        df.loc[i,'team']=df.loc[i,'home team']\n    i+=1\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soru 15\ndfLeBronJamess = df.loc[df[\"shoot player\"] == 'LeBron James']\ndfLeBronJames= dfLeBronJamess.loc[dfLeBronJamess[\"current shot outcome\"] == 'SCORED']\ndfLeBronJames1= dfLeBronJamess.loc[dfLeBronJamess[\"current shot outcome\"] == 'MISSED']\n\ndfLeBronJames=dfLeBronJames.loc[0:13550,['current shot outcome','team']]\ndfLeBronJames1=dfLeBronJames1.loc[0:13550,['current shot outcome','team']]\n\ndfLeBronJames=dfLeBronJames.groupby(['team']).count()\ndfLeBronJames1=dfLeBronJames1.groupby(['team']).count()\npd.DataFrame(data=dfLeBronJames)\npd.DataFrame(data=dfLeBronJames1)\ncombine=dfLeBronJames.join(dfLeBronJames1,lsuffix='_SCORED',rsuffix='_MISSED')\ncombine","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 17\ndfCleveland = df.loc[df[\"CLE team\"] == 'CLE']\ndf3=dfCleveland.groupby(['shoot player','team']).HomeAway.count()\ndf3=df3.sort_values(ascending=False)    \ndf3.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 18\ndf=df.fillna(0)\ndg = df.astype({'Unnamed: 0':'float','location x':'int','location y':'int','points':'float','time from last shot':'int','quarter':'float','points_gained':'int','difference':'float'})\ndg.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 19\nprint(\"Toplam boş olan satır sayısı:\",df['self previous shot'].isnull().sum())\n#Yes, it must be filled, because otherwise, incorrect information may be obtained in data types and operations. filled in in previous questions.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 21\nprint(\"2 ayrı dataframe birleştirirken 2 farklı yol vardır. Biri concat diğeri join'dir.Concat 2 dataframe' birleştirirken alt alta ekler. Başka bir değişim uygulamaz. Join ise eğer ortak veri sütunumuz var ise bunu indeks olarak gönderebilir,diğer oratk olanlara hangi frameden geldiğini anlama amacıyla ek isimler vererek ayrım yapabiliriz..\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 22\nimport seaborn as sns\nsns.lmplot(x=\"location x\", y=\"location y\", hue=\"current shot outcome\", data=df) #Shots in the 200-400 range are successful. In the 400-600 range, they are generally unsuccessful.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"player position\", y=\"location y\", hue=\"current shot outcome\",#there are similar increments between location y and position locations\n                 data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"points\", y=\"difference\", hue=\"current shot outcome\",#As the difference increased, the shot success rate and the number of shots increased.\n                 data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ay = sns.barplot(x=\"self previous shot\", y=\"time from last shot\", hue=\"current shot outcome\",#The time elapsed after the previous shot increased the probability of a successful shot.\n                 data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 22\na = {'SCORED':1, 'MISSED':0, 'BLOCKED':-1}\ndf['self previous shot'] = df['self previous shot'].map(a)\n\nb = {'PG':1, 'PF':2, 'SF':3, 'SG':4, 'C':5, 'F':6, 'G':7}\ndf['player position'] = df['player position'].map(b)\n\nc = {'No':0, 'Yes':1}\ndf['home game'] = df['home game'].map(c)\n\nd = {'SCORED':1, 'MISSED':0, 'BLOCKED':-1}\ndf['opponent previous shot'] = df['opponent previous shot'].map(d)\n\ne = {'CLE':1, 'TOR':2, 'PHI':3, 'WAS':4, 'IND':5, 'MIL':6, 'CHI':7, 'NYK':8, 'MEM':9,\n       'CHA':10, 'BRO':11, 'PHX':12, 'UTA':13, 'POR':14, 'SAC':15, 'GSW':16, 'NOP':17, 'DAL':18,\n       'OKL':19, 'MIN':20, 'BOS':21, 'ATL':22, 'MIA':23, 'ORL':24, 'HOU':25, 'LAC':26, 'LAL':27,\n       'DEN':28, 'SAS':29}\ndf['home team'] = df['home team'].map(e)\n\nf = {'CLE':1, 'TOR':2, 'PHI':3, 'WAS':4, 'IND':5, 'MIL':6, 'CHI':7, 'NYK':8, 'MEM':9,\n       'CHA':10, 'BRO':11, 'PHX':12, 'UTA':13, 'POR':14, 'SAC':15, 'GSW':16, 'NOP':17, 'DAL':18,\n       'OKL':19, 'MIN':20, 'BOS':21, 'ATL':22, 'MIA':23, 'ORL':24, 'HOU':25, 'LAC':26, 'LAL':27,\n       'DEN':28, 'SAS':29}\ndf['away team'] = df['away team'].map(f)\n\ng = {'OPP':1, 'CLE':0}\ndf['My_Team'] = df['My_Team'].map(g)\n\nk = {'SCORED':1, 'MISSED':0, 'BLOCKED':-1}\ndf['current shot outcome'] = df['current shot outcome'].map(k)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nı = {'Driving Layup':1, 'Hook Shot':2, 'Jump Shot':3, 'Tip Layup Shot':4,\n       'Running Dunk':5, 'Cutting Layup Shot':6, 'Floating Jump Shot':7,\n       'Turnaround Jump Shot':8, 'Layup':50, 'Running Layup':9, 'Alley Oop Dunk':10,\n       'Putback Dunk':11, 'Step Back Jump Shot':12, 'Running Reverse Layup':13,\n       'Pullup Jump Shot':14, 'Fadeaway Jumper':15, 'Dunk':16, 'Driving Dunk':17,\n       'Finger Roll Layup':18, 'Jump Bank Shot':19, 'Driving Bank Shot':20,\n       'Turnaround Hook Shot':21, 'Driving Floating Jump Shot':22,\n       'Driving Finger Roll Layup':23, 'Reverse Layup':24, 'Putback Layup':25,\n       'Pullup Bank Shot':26, 'Turnaround Fadeaway':26, 'Driving Reverse Layup':27,\n       'Driving Hook Shot':28, 'Cutting Dunk Shot':29, 'Running Jump Shot':30,\n       'Driving Floating Bank Jump Shot':31, 'Turnaround Fadeaway Shot':32,\n       'Tip Dunk Shot':33, 'Running Finger Roll Layup':34, 'Alley Oop Layup':35,\n       'Turnaround Bank Shot':36, 'Reverse Dunk':37,\n       'Running Alley Oop Layup Shot':38, 'Running Pull-Up Jump Shot':38,\n       'Turnaround Bank Hook Shot':39, 'Fadeaway Bank Shot':40,\n       'Hook Bank Shot':41, 'Cutting Finger Roll Layup Shot':42,\n       'Step Back Bank Jump Shot':43, 'Running Alley Oop Dunk Shot':44,\n       'Driving Reverse Dunk Shot':45, 'Turnaround Fadeaway Bank Jump Shot':46,\n       'Driving Bank Hook Shot':47, 'Running Hook Shot':48,\n       'Running Reverse Dunk Shot':49}\ndf['shot type'] = df['shot type'].map(ı)\ndf=df.fillna(0)\ndf.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(x=\"shot type\", y=\"location x\", hue=\"current shot outcome\", data=df)#The shot was taken from places close to the basket.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 23 Başlangıç\ndf.drop(['self previous shot','opponent previous shot','time from last shot'], axis=1)\nfeatures=['player position','home game','location x','home team','shot type','points','away team','location y','quarter','My_Team','difference']\nX =df[features]\ny=df['current shot outcome']\n\ndf\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 20\ndf1=df.rename(columns = {\"self previous shot\":\"kendi takımının bir önceki şutunun sonucu\",\"player position\":\"Şutu atan oyuncunun hangi pozisyonda oynadığı\",\"home game\":\"ev_sahibi\",\"location x\":\"x_konumu\",\"opponent previous shot\":\"rakip takımın bir önceki şutunun sonucu\",\"home team\":\"Evinde oynayan takımın kısaltması\",\"shot type\":\"Şutun tipi\",\n                        \"points\":\"puan\",\"away team\":\"deplasmanda oynayan takımın kısaltması\",\"location y\":\"y_konumu\",\"time\":\"zaman\",\"date\":\"tarih\",\"shoot player\":\"sutu_atan_oyuncu\",\"time from last shot\":\"Oyuncunun takımının bir önceki şutundan kaç saniye sonra şut attığı\",\"quarter\":\"çeyrek\",\"current shot outcome\":\"su_anki_atis_sonucu\",\"My_Team\":\"benim_takimim\",\"HomeAway\":\"Home team ve away team's birleştirilmiş hali\",\n                        \"points_gained\":\"kazanilan_puanlar\",\"difference\":\"fark\"})\ndf1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 23\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 24\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Define model. Specify a number for random_state to ensure same results each run\niowa_model = DecisionTreeRegressor(random_state=1)\n\n# Fit model\niowa_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Soru 25\nprint(\"Making predictions for the following 5 match:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(iowa_model.predict(X.head()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\npredicted_match_score = iowa_model.predict(X)\nmean_absolute_error(y, predicted_match_score)\nprint(\"Bu tahminler ile ileride karşılaşılabilecek hataları farkedebilmek daha iyi sonuçlar elde edebilmek ve daha çok veri vererek daha güvenilir bilgiler elde etmek için tercih edilir.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n    model.fit(X_train, y_train)\n    preds_val = model.predict(X_test)\n    mae = mean_absolute_error(y_test, preds_val)\n    return(mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, X_train, X_test, y_train,y_test)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Soru 26\nprint(\"Random Forest'ta max_leaf_nodes kullanılır.Ancak None olarak kendisi verildiğinden pek tercih edilmez. DesicionTree de tercih edilmesi performans açısından çok daha iyidir\")\nclass sklearn.ensemble.RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',**** max_leaf_nodes=None,****\nmin_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)[source]","metadata":{}},{"cell_type":"code","source":"#Soru 27\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\ndef get_ma(max_leaf_nodes, X_train, X_test, y_train, y_test):\n    forest_model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n    forest_model.fit(X_train, y_train)\n    melb_preds= forest_model.predict(X_test)\n    ma = mean_absolute_error(y_test, melb_preds)\n    return(ma)\n\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_ma = get_ma(max_leaf_nodes, X_train, X_test, y_train,y_test)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_ma))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Soru 28\n Random Forest'ın Avantajları \n 1. Random Forest, torbalama algoritmasına dayanır ve Ensemble Learning tekniğini kullanır. Verilerin alt kümesinde olabildiğince çok ağaç oluşturur ve tüm ağaçların çıktısını birleştirir.\n Bu şekilde karar ağaçlarında aşırı uydurma sorununu azaltır ve ayrıca varyansı azaltır  ve dolayısıyla doğruluğu artırır .\n 2. Random Forest, hem sınıflandırma hem de regresyon problemlerini çözmek için kullanılabilir .\n3.  Random Forest, hem  kategorik hem de sürekli değişkenlerle iyi çalışır .\n4. Random Forest, eksik değerleri otomatik olarak işleyebilir . \n5. Özellik ölçeklendirmesi gerekmez:Random Forest durumunda, mesafe hesaplaması yerine kural tabanlı yaklaşımı kullandığı için özellik ölçeklendirmesi (standartlaştırma ve normalleştirme) gerekmez. \n6. Doğrusal olmayan parametreleri verimli bir şekilde işler: Doğrusal olmayan parametreler, eğri tabanlı algoritmaların aksine bir Random Forest'ın performansını etkilemez. Bu nedenle, bağımsız değişkenler arasında yüksek düzeyde doğrusal olmama durumu varsa, Random Forest, diğer eğri tabanlı algoritmalara kıyasla daha iyi performans gösterebilir.\n7. Random Forest, eksik değerleri otomatik olarak işleyebilir.\n8. Random Forest genellikle aykırı değerlere karşı dayanıklıdır ve bunları otomatik olarak işleyebilir. \n9. Random Forest algoritması çok kararlıdır . Veri kümesine yeni bir veri noktası eklense bile, yeni veriler bir ağacı etkileyebileceğinden genel algoritma fazla etkilenmez, ancak tüm ağaçları etkilemesi çok zordur.\n10. Random Forest gürültüden nispeten daha az etkilenir .\nRandom Forest'ın Dezavantajları \n1. Karmaşıklık:\nRandom Forest çok sayıda ağaç oluşturur (karar ağacında sadece bir ağacın aksine) ve çıktılarını birleştirir. Varsayılan olarak Python sklearn kitaplığında 100 ağaç oluşturur. Bunu yapmak için, bu algoritma çok daha fazla hesaplama gücü ve kaynağı gerektirir. Öte yandan karar ağacı basittir ve çok fazla hesaplama kaynağı gerektirmez.\n2. Daha Uzun Eğitim Süresi: Random Forest, çok sayıda ağaç ürettiğinden (karar ağacı olması durumunda bir ağaç yerine) ve oyların çoğunluğuyla karar verdiğinden, karar ağaçlarına kıyasla çok daha fazla eğitim süresi gerektirir.\n","metadata":{}},{"cell_type":"markdown","source":"Karar Ağacının Avantajları\n1. Net Görselleştirme :  Fikir çoğunlukla günlük hayatımızda kullanıldığı için algoritmanın anlaşılması, yorumlanması ve görselleştirilmesi kolaydır. Bir Karar Ağacının çıktısı insanlar tarafından kolaylıkla yorumlanabilir. \n2. Basit ve anlaşılması kolay : Karar Ağacı , anlaşılması çok kolay olan basit  if-else ifadelerine benzer. \n3. Karar Ağacı hem sınıflandırma hem de regresyon problemleri için kullanılabilir .\n4. Karar Ağacı  , hem sürekli hem de kategorik değişkenleri işleyebilir \n5. Özellik ölçekleme gerektirmez : Karar Ağacı durumunda, mesafe hesaplaması yerine kural tabanlı yaklaşımı kullandığı için özellik ölçeklendirmesine (standartlaştırma ve normalleştirme) gerek yoktur.\n6. Doğrusal olmayan parametreleri verimli bir şekilde işler:  Doğrusal olmayan parametreler, eğri tabanlı algoritmaların aksine Karar Ağacının performansını etkilemez. Bu nedenle, bağımsız değişkenler arasında yüksek doğrusalsızlık varsa, Karar Ağaçları diğer eğri tabanlı algoritmalara kıyasla daha iyi performans gösterebilir.\n7. Karar Ağacı, eksik değerleri otomatik olarak işleyebilir .\n8. Karar Ağacı genellikle aykırı değerlere karşı dayanıklıdır ve bunları otomatik olarak işleyebilir.\n9 . Daha Az Eğitim Süresi : Eğitim süresi Random Forest'a göre daha kısadır çünkü Random Fores'daki ağaç ormanından farklı olarak sadece bir ağaç oluşturur.\n\nKarar Ağacının Dezavantajları \n1. Fazla Uyum: Karar Ağacının temel sorunu budur. Genellikle, sonuçta yanlış tahminlere yol açan verilerin aşırı takılmasına yol açar. Verileri (gürültülü veriler bile) sığdırmak için yeni düğümler üretmeye devam eder ve nihayetinde ağaç yorumlanamayacak kadar karmaşık hale gelir. Bu şekilde genelleme kabiliyetini kaybeder. Eğitilmiş veriler üzerinde çok iyi performans gösterir ancak görünmeyen veriler üzerinde çok fazla hata yapmaya başlar. \n\n2. Yüksek varyans: 1. maddede bahsedildiği gibi, Karar Ağacı genellikle verilerin fazla takılmasına yol açar. Fazla uydurma nedeniyle, çıktıda çok yüksek varyans olasılığı vardır, bu da nihai tahminde birçok hataya yol açar ve sonuçlarda yüksek yanlışlık gösterir. Sıfır yanlılık (fazla uydurma) elde etmek için yüksek varyansa yol açar.\n3. Kararsız: Yeni bir veri noktası eklemek, genel ağacın yeniden oluşturulmasına yol açabilir ve tüm düğümlerin yeniden hesaplanması ve yeniden oluşturulması gerekir.\n4. Gürültüden etkilenir: Birazcık gürültü onu kararsız hale getirebilir ve bu da yanlış tahminlere yol açar.\n5. Büyük veri kümeleri için uygun değildir:\n\n\nVeri boyutu büyükse, tek bir ağaç karmaşıklaşabilir ve fazla uyum sağlamaya neden olabilir. Yani bu durumda, tek bir Karar Ağacı yerine Random Forest kullanmalıyız. Karar Ağacının sınırlamalarını aşmak için tek bir ağaca dayanmayan Random Forest kullanmalıyız. Bir ağaç ormanı oluşturur ve oy sayısına göre karar verir. Random Forest, Ensemble Learning tekniklerinden biri olan torbalama yöntemine dayanmaktadır .","metadata":{}}]}